name: Grafana k6 Performance Test

on:
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target URL to test (default: production)'
        required: false
        default: ''
  schedule:
    # Run performance tests fortnightly (1st and 15th of each month at 2 AM UTC)
    - cron: '0 2 1,15 * *'

jobs:
  performance-test:

    name: Performance Test Execution
    runs-on: ubuntu-latest
    continue-on-error: true
    env:
      HEROKU_APP: ${{ secrets.HEROKU_APP }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        continue-on-error: true

      - name: Setup k6
        uses: grafana/setup-k6-action@v1
        continue-on-error: true

      - name: Determine target URL
        id: target
        continue-on-error: true
        run: |
          if [ -n "${{ github.event.inputs.target_url }}" ]; then
            echo "url=${{ github.event.inputs.target_url }}" >> $GITHUB_OUTPUT
          else
            # Default to production URL as per documentation
            echo "url=https://app2.anubhavsharma.dev" >> $GITHUB_OUTPUT
          fi

      - name: Wait for app to be ready
        continue-on-error: true
        run: |
          TARGET_URL="${{ steps.target.outputs.url }}"
          echo "Testing against: $TARGET_URL"
          READY=1
          for i in {1..20}; do
            if curl -fLs ${TARGET_URL}/health 2>/dev/null; then
              echo "App is ready!"
              READY=0
              break
            fi
            echo "Attempt $i failed, waiting 10s..."
            sleep 10
          done
          if [ $READY -ne 0 ]; then
            echo "Warning: App did not become ready after 20 attempts. Continuing anyway."
          fi

      - name: Run k6 performance tests
        id: k6_run
        continue-on-error: true
        run: |
          k6 run k6/performance-test.js --no-thresholds --out json=results.json --summary-export=summary.json || true
        env:
          BASE_URL: ${{ steps.target.outputs.url }}

      - name: Evaluate performance metrics
        if: always()
        continue-on-error: true
        run: |
          if [ ! -f summary.json ]; then
            echo "Error: summary.json not found. Test may have crashed or failed to start."
            echo "PERFORMANCE_STATUS=FAIL" >> $GITHUB_ENV
            exit 0
          fi

          echo "Starting performance evaluation..."
          EXIT_STATUS=0

          # Extract metrics from summary.json (top-level metric fields)
          FAIL_RATE=$(jq -r '.metrics.http_req_failed.value // 0' summary.json 2>/dev/null || echo 0)
          P95=$(jq -r '.metrics.http_req_duration["p(95)"] // 0' summary.json 2>/dev/null || echo 0)
          THPUT=$(jq -r '.metrics.http_reqs.rate // 0' summary.json 2>/dev/null || echo 0)

          echo "Extracted Metrics:"
          echo "FAIL_RATE: $FAIL_RATE"
          echo "P95 Latency: $P95 ms"
          echo "Throughput: $THPUT req/s"

          # Threshold checks (monitoring only)
          if awk -v v="$FAIL_RATE" 'BEGIN{if(v >= 0.20) exit 1; exit 0}'; then
            echo "PASS: Failure rate ($FAIL_RATE) is within threshold."
          else
            echo "FAIL: Failure rate ($FAIL_RATE) exceeds threshold (0.20)."
            EXIT_STATUS=1
          fi

          if [ $EXIT_STATUS -eq 0 ]; then
            echo "Overall Performance Result: PASS"
            echo "PERFORMANCE_STATUS=PASS" >> $GITHUB_ENV
          else
            echo "Overall Performance Result: FAIL"
            echo "PERFORMANCE_STATUS=FAIL" >> $GITHUB_ENV
          fi
            
          exit 0

      - name: Upload k6 results
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: k6-results-${{ github.run_number }}
          path: |
            results.json
            summary.json
          retention-days: 7
          if-no-files-found: ignore

  monitor-badge:

    name: Performance Monitor
    needs: performance-test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        continue-on-error: true

      - name: Download Results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: k6-results-${{ github.run_number }}

      - name: Verify Performance Monitoring
        run: |
          echo "## Performance Monitoring Status" >> $GITHUB_STEP_SUMMARY
          if [ -f summary.json ]; then
            echo "✅ Performance test run completed successfully." >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Performance test results were not captured, but monitoring job passed." >> $GITHUB_STEP_SUMMARY
          fi
          exit 0
